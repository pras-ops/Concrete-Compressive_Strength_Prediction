{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop([\"concrete_compressive_strength\"],axis=1)\n",
    "y=df[\"concrete_compressive_strength\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(666, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building using Deep Learning(Keras Sequential Model)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models,layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(100,activation='relu',input_shape=(x_train.iloc[1].shape)))\n",
    "model.add(layers.Dropout(0.7))\n",
    "model.add(layers.Dense(5,activation='tanh'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "666/666 [==============================] - 2s 2ms/step - loss: 1456.6409 - mae: 34.2778 - val_loss: 1218.0251 - val_mae: 30.6911\n",
      "Epoch 2/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 1264.7738 - mae: 31.2163 - val_loss: 1081.2435 - val_mae: 28.3976\n",
      "Epoch 3/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 1083.3245 - mae: 28.2319 - val_loss: 934.3132 - val_mae: 25.7271\n",
      "Epoch 4/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 921.9830 - mae: 25.4846 - val_loss: 798.3171 - val_mae: 23.0851\n",
      "Epoch 5/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 792.7288 - mae: 23.2132 - val_loss: 682.2318 - val_mae: 20.8444\n",
      "Epoch 6/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 682.7947 - mae: 21.1574 - val_loss: 585.7451 - val_mae: 19.0593\n",
      "Epoch 7/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 591.4199 - mae: 19.3766 - val_loss: 507.2304 - val_mae: 17.5018\n",
      "Epoch 8/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 524.4102 - mae: 18.2741 - val_loss: 446.2053 - val_mae: 16.1987\n",
      "Epoch 9/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 478.8269 - mae: 17.1511 - val_loss: 400.1849 - val_mae: 15.2190\n",
      "Epoch 10/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 428.1767 - mae: 16.1537 - val_loss: 366.8344 - val_mae: 14.5815\n",
      "Epoch 11/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 403.4704 - mae: 15.6391 - val_loss: 341.5152 - val_mae: 14.1340\n",
      "Epoch 12/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 377.5943 - mae: 15.2388 - val_loss: 322.4217 - val_mae: 13.8103\n",
      "Epoch 13/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 373.3720 - mae: 15.2625 - val_loss: 310.0672 - val_mae: 13.6013\n",
      "Epoch 14/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 351.2055 - mae: 14.6554 - val_loss: 300.1481 - val_mae: 13.4249\n",
      "Epoch 15/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 337.2687 - mae: 14.4992 - val_loss: 292.9590 - val_mae: 13.3016\n",
      "Epoch 16/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 335.3631 - mae: 14.5495 - val_loss: 288.4376 - val_mae: 13.2179\n",
      "Epoch 17/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 355.7160 - mae: 15.0490 - val_loss: 285.9626 - val_mae: 13.1717\n",
      "Epoch 18/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 336.3898 - mae: 14.4542 - val_loss: 283.6529 - val_mae: 13.1362\n",
      "Epoch 19/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 335.0898 - mae: 14.5415 - val_loss: 281.6111 - val_mae: 13.1111\n",
      "Epoch 20/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 331.3758 - mae: 14.3465 - val_loss: 280.1582 - val_mae: 13.0923\n",
      "Epoch 21/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 340.8990 - mae: 14.9252 - val_loss: 279.3435 - val_mae: 13.0863\n",
      "Epoch 22/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 330.6342 - mae: 14.4776 - val_loss: 278.5662 - val_mae: 13.0860\n",
      "Epoch 23/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 342.7094 - mae: 15.0813 - val_loss: 278.0973 - val_mae: 13.0883\n",
      "Epoch 24/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 324.1214 - mae: 14.2891 - val_loss: 277.7295 - val_mae: 13.0962\n",
      "Epoch 25/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 325.8411 - mae: 14.5572 - val_loss: 277.5734 - val_mae: 13.1004\n",
      "Epoch 26/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 332.4406 - mae: 14.5025 - val_loss: 277.4576 - val_mae: 13.1038\n",
      "Epoch 27/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 324.9198 - mae: 14.3721 - val_loss: 277.4220 - val_mae: 13.1049\n",
      "Epoch 28/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 320.9854 - mae: 14.2496 - val_loss: 277.0326 - val_mae: 13.1210\n",
      "Epoch 29/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 324.8638 - mae: 14.3537 - val_loss: 276.9456 - val_mae: 13.1258\n",
      "Epoch 30/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 315.4785 - mae: 14.4544 - val_loss: 276.8350 - val_mae: 13.1323\n",
      "Epoch 31/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 323.1787 - mae: 14.3685 - val_loss: 276.8016 - val_mae: 13.1345\n",
      "Epoch 32/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 323.3017 - mae: 14.3804 - val_loss: 276.8022 - val_mae: 13.1345\n",
      "Epoch 33/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 323.6846 - mae: 14.5933 - val_loss: 276.7584 - val_mae: 13.1374\n",
      "Epoch 34/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 338.8841 - mae: 14.7296 - val_loss: 276.7263 - val_mae: 13.1396\n",
      "Epoch 35/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 319.9531 - mae: 14.4599 - val_loss: 276.6971 - val_mae: 13.1417\n",
      "Epoch 36/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 328.0503 - mae: 14.4202 - val_loss: 276.6113 - val_mae: 13.1480\n",
      "Epoch 37/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 331.4355 - mae: 14.6472 - val_loss: 276.7451 - val_mae: 13.1383\n",
      "Epoch 38/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 330.8392 - mae: 14.6568 - val_loss: 276.6473 - val_mae: 13.1453\n",
      "Epoch 39/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 326.5338 - mae: 14.3776 - val_loss: 276.6858 - val_mae: 13.1425\n",
      "Epoch 40/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 321.2107 - mae: 14.3598 - val_loss: 276.6156 - val_mae: 13.1477\n",
      "Epoch 41/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 336.8390 - mae: 14.7888 - val_loss: 276.6546 - val_mae: 13.1447\n",
      "Epoch 42/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 348.3737 - mae: 14.7999 - val_loss: 276.6032 - val_mae: 13.1486\n",
      "Epoch 43/100\n",
      "666/666 [==============================] - 1s 2ms/step - loss: 318.8908 - mae: 14.4238 - val_loss: 276.6500 - val_mae: 13.1451\n",
      "Epoch 44/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 309.0722 - mae: 14.2174 - val_loss: 276.6100 - val_mae: 13.1481\n",
      "Epoch 45/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 317.4574 - mae: 14.4500 - val_loss: 276.6029 - val_mae: 13.1487\n",
      "Epoch 46/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 316.9937 - mae: 14.4787 - val_loss: 276.5197 - val_mae: 13.1554\n",
      "Epoch 47/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 328.0276 - mae: 14.5319 - val_loss: 276.4790 - val_mae: 13.1589\n",
      "Epoch 48/100\n",
      "666/666 [==============================] - 1s 884us/step - loss: 334.9632 - mae: 14.5926 - val_loss: 276.4394 - val_mae: 13.1625\n",
      "Epoch 49/100\n",
      "666/666 [==============================] - 1s 911us/step - loss: 333.0387 - mae: 14.5446 - val_loss: 276.4178 - val_mae: 13.1645\n",
      "Epoch 50/100\n",
      "666/666 [==============================] - 1s 830us/step - loss: 324.7319 - mae: 14.4670 - val_loss: 276.4572 - val_mae: 13.1608\n",
      "Epoch 51/100\n",
      "666/666 [==============================] - 1s 830us/step - loss: 328.9267 - mae: 14.5876 - val_loss: 276.4992 - val_mae: 13.1571\n",
      "Epoch 52/100\n",
      "666/666 [==============================] - 1s 949us/step - loss: 334.2724 - mae: 14.7675 - val_loss: 276.5319 - val_mae: 13.1544\n",
      "Epoch 53/100\n",
      "666/666 [==============================] - 1s 907us/step - loss: 324.3160 - mae: 14.3970 - val_loss: 276.6217 - val_mae: 13.1472\n",
      "Epoch 54/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 322.6084 - mae: 14.4447 - val_loss: 276.5259 - val_mae: 13.1548\n",
      "Epoch 55/100\n",
      "666/666 [==============================] - 1s 1ms/step - loss: 337.3479 - mae: 14.5445 - val_loss: 276.5662 - val_mae: 13.1515\n",
      "Epoch 56/100\n",
      "666/666 [==============================] - 1s 936us/step - loss: 317.1984 - mae: 14.4859 - val_loss: 276.5121 - val_mae: 13.1560\n",
      "Epoch 57/100\n",
      "666/666 [==============================] - 1s 982us/step - loss: 318.9772 - mae: 14.3267 - val_loss: 276.5995 - val_mae: 13.1489\n",
      "Epoch 58/100\n",
      "666/666 [==============================] - 1s 860us/step - loss: 338.6811 - mae: 14.9169 - val_loss: 276.7100 - val_mae: 13.1408\n",
      "Epoch 59/100\n",
      "666/666 [==============================] - 1s 939us/step - loss: 316.5864 - mae: 14.2978 - val_loss: 276.6817 - val_mae: 13.1428\n",
      "Epoch 60/100\n",
      "666/666 [==============================] - 1s 786us/step - loss: 318.5291 - mae: 14.2821 - val_loss: 276.6843 - val_mae: 13.1426\n",
      "Epoch 61/100\n",
      "666/666 [==============================] - 1s 854us/step - loss: 326.3585 - mae: 14.5881 - val_loss: 276.6766 - val_mae: 13.1431\n",
      "Epoch 62/100\n",
      "666/666 [==============================] - 1s 853us/step - loss: 315.4549 - mae: 14.2303 - val_loss: 276.6280 - val_mae: 13.1467\n",
      "Epoch 63/100\n",
      "666/666 [==============================] - 1s 882us/step - loss: 325.5208 - mae: 14.4444 - val_loss: 276.6035 - val_mae: 13.1486\n",
      "Epoch 64/100\n",
      "666/666 [==============================] - 1s 797us/step - loss: 314.2755 - mae: 14.2393 - val_loss: 276.4756 - val_mae: 13.1592\n",
      "Epoch 65/100\n",
      "666/666 [==============================] - 1s 887us/step - loss: 331.6207 - mae: 14.4518 - val_loss: 276.5232 - val_mae: 13.1551\n",
      "Epoch 66/100\n",
      "666/666 [==============================] - 1s 812us/step - loss: 304.5407 - mae: 13.9902 - val_loss: 276.4042 - val_mae: 13.1659\n",
      "Epoch 67/100\n",
      "666/666 [==============================] - 1s 853us/step - loss: 339.6308 - mae: 14.5768 - val_loss: 276.4886 - val_mae: 13.1580\n",
      "Epoch 68/100\n",
      "666/666 [==============================] - 1s 890us/step - loss: 326.8530 - mae: 14.5806 - val_loss: 276.5361 - val_mae: 13.1540\n",
      "Epoch 69/100\n",
      "666/666 [==============================] - 1s 832us/step - loss: 329.6584 - mae: 14.6456 - val_loss: 276.5884 - val_mae: 13.1498\n",
      "Epoch 70/100\n",
      "666/666 [==============================] - 1s 841us/step - loss: 330.6207 - mae: 14.5613 - val_loss: 276.6277 - val_mae: 13.1468\n",
      "Epoch 71/100\n",
      "666/666 [==============================] - 1s 832us/step - loss: 329.7620 - mae: 14.8053 - val_loss: 276.6408 - val_mae: 13.1458\n",
      "Epoch 72/100\n",
      "666/666 [==============================] - 1s 857us/step - loss: 315.1905 - mae: 14.2520 - val_loss: 276.4569 - val_mae: 13.1609\n",
      "Epoch 73/100\n",
      "666/666 [==============================] - 1s 780us/step - loss: 322.8672 - mae: 14.3540 - val_loss: 276.3781 - val_mae: 13.1685\n",
      "Epoch 74/100\n",
      "666/666 [==============================] - 1s 932us/step - loss: 324.8199 - mae: 14.4510 - val_loss: 276.3460 - val_mae: 13.1718\n",
      "Epoch 75/100\n",
      "666/666 [==============================] - 1s 785us/step - loss: 328.2215 - mae: 14.5957 - val_loss: 276.3993 - val_mae: 13.1663\n",
      "Epoch 76/100\n",
      "666/666 [==============================] - 1s 868us/step - loss: 309.0280 - mae: 14.1072 - val_loss: 276.2830 - val_mae: 13.1791\n",
      "Epoch 77/100\n",
      "666/666 [==============================] - 1s 805us/step - loss: 334.3800 - mae: 14.6698 - val_loss: 276.3698 - val_mae: 13.1693\n",
      "Epoch 78/100\n",
      "666/666 [==============================] - 1s 926us/step - loss: 323.7090 - mae: 14.5281 - val_loss: 276.3380 - val_mae: 13.1727\n",
      "Epoch 79/100\n",
      "666/666 [==============================] - 1s 997us/step - loss: 314.9942 - mae: 14.2233 - val_loss: 276.4052 - val_mae: 13.1658\n",
      "Epoch 80/100\n",
      "666/666 [==============================] - 1s 804us/step - loss: 307.6700 - mae: 14.0486 - val_loss: 276.2957 - val_mae: 13.1776\n",
      "Epoch 81/100\n",
      "666/666 [==============================] - 1s 861us/step - loss: 319.2499 - mae: 14.4174 - val_loss: 276.3352 - val_mae: 13.1730\n",
      "Epoch 82/100\n",
      "666/666 [==============================] - 1s 780us/step - loss: 329.0853 - mae: 14.6293 - val_loss: 276.3514 - val_mae: 13.1713\n",
      "Epoch 83/100\n",
      "666/666 [==============================] - 1s 867us/step - loss: 327.1313 - mae: 14.6564 - val_loss: 276.3003 - val_mae: 13.1770\n",
      "Epoch 84/100\n",
      "666/666 [==============================] - 1s 858us/step - loss: 321.3706 - mae: 14.2788 - val_loss: 276.2778 - val_mae: 13.1798\n",
      "Epoch 85/100\n",
      "666/666 [==============================] - 1s 903us/step - loss: 314.8052 - mae: 14.2572 - val_loss: 276.2813 - val_mae: 13.1793\n",
      "Epoch 86/100\n",
      "666/666 [==============================] - 1s 817us/step - loss: 325.3621 - mae: 14.5338 - val_loss: 276.2783 - val_mae: 13.1797\n",
      "Epoch 87/100\n",
      "666/666 [==============================] - 1s 840us/step - loss: 323.8526 - mae: 14.3978 - val_loss: 276.2918 - val_mae: 13.1781\n",
      "Epoch 88/100\n",
      "666/666 [==============================] - 1s 819us/step - loss: 328.3681 - mae: 14.6757 - val_loss: 276.2240 - val_mae: 13.1871\n",
      "Epoch 89/100\n",
      "666/666 [==============================] - 1s 840us/step - loss: 321.9139 - mae: 14.4067 - val_loss: 276.2025 - val_mae: 13.1904\n",
      "Epoch 90/100\n",
      "666/666 [==============================] - 1s 920us/step - loss: 326.7872 - mae: 14.3070 - val_loss: 276.2220 - val_mae: 13.1874\n",
      "Epoch 91/100\n",
      "666/666 [==============================] - 1s 868us/step - loss: 324.4379 - mae: 14.6198 - val_loss: 276.2470 - val_mae: 13.1838\n",
      "Epoch 92/100\n",
      "666/666 [==============================] - 1s 834us/step - loss: 322.5238 - mae: 14.3872 - val_loss: 276.2645 - val_mae: 13.1815\n",
      "Epoch 93/100\n",
      "666/666 [==============================] - 1s 824us/step - loss: 336.1495 - mae: 14.4152 - val_loss: 276.3254 - val_mae: 13.1741\n",
      "Epoch 94/100\n",
      "666/666 [==============================] - 1s 795us/step - loss: 312.7943 - mae: 14.1716 - val_loss: 276.2223 - val_mae: 13.1873\n",
      "Epoch 95/100\n",
      "666/666 [==============================] - 1s 878us/step - loss: 315.2018 - mae: 14.3984 - val_loss: 276.2208 - val_mae: 13.1876\n",
      "Epoch 96/100\n",
      "666/666 [==============================] - 1s 838us/step - loss: 326.9612 - mae: 14.5162 - val_loss: 276.2267 - val_mae: 13.1867\n",
      "Epoch 97/100\n",
      "666/666 [==============================] - 1s 786us/step - loss: 309.3936 - mae: 14.1870 - val_loss: 276.2225 - val_mae: 13.1873\n",
      "Epoch 98/100\n",
      "666/666 [==============================] - 1s 846us/step - loss: 330.7203 - mae: 14.6029 - val_loss: 276.3138 - val_mae: 13.1755\n",
      "Epoch 99/100\n",
      "666/666 [==============================] - 1s 791us/step - loss: 322.7981 - mae: 14.4693 - val_loss: 276.4510 - val_mae: 13.1614\n",
      "Epoch 100/100\n",
      "666/666 [==============================] - 1s 862us/step - loss: 308.1035 - mae: 14.1643 - val_loss: 276.3861 - val_mae: 13.1677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29ce9e299d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=100,batch_size=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 276.3860 - mae: 13.1677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[276.385986328125, 13.167662620544434]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34.275978], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict(x_test)\n",
    "pred[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
